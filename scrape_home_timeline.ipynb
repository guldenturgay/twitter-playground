{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f94c4a90f28a7fbd719ec002f9c893ca4c4858f29751705a64e5fc8dfb9b9070"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Scraping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from autocorrect import Speller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more information about Twitter API credentials please read README.md file\n",
    "# Get credentials from .env file\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "API_SECRET_KEY = os.getenv('API_SECRET_KEY')\n",
    "ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')\n",
    "ACCESS_TOKEN_SECRET = os.getenv('ACCESS_TOKEN_SECRET')\n",
    "\n",
    "\n",
    "# authenticate\n",
    "auth = tw.OAuthHandler(API_KEY, API_SECRET_KEY)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          tweet_text\n",
       "0  Americans should never have to fear discrimina...\n",
       "1  Eleven years ago, the Affordable Care Act beca...\n",
       "2  One year ago we had to close the West Seattle ...\n",
       "3  RT @erikashimizu: I'm building a referral list...\n",
       "4  Programmed 3 hours of experimental movies for ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Americans should never have to fear discrimina...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Eleven years ago, the Affordable Care Act beca...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One year ago we had to close the West Seattle ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RT @erikashimizu: I'm building a referral list...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Programmed 3 hours of experimental movies for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "timeline = api.home_timeline(count=200)\n",
    "\n",
    "\n",
    "tweets = []\n",
    "for tweet in timeline:\n",
    "    text = api.get_status(id=tweet.id, tweet_mode = 'extended', lan='en').full_text\n",
    "    tweets.append(text)\n",
    "    home_timeline_tweets = pd.DataFrame(tweets, columns=['tweet_text'])\n",
    "\n",
    "home_timeline_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'RT @ehimeora: You took care of everybody else, it’s now time to take care of yourself too.'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "home_timeline_tweets['tweet_text'][14]"
   ]
  },
  {
   "source": [
    "# Data Cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          tweet_text\n",
       "0  americans should never have to fear discrimina...\n",
       "1  eleven years ago the affordable care act becam...\n",
       "2  one year ago we had to close the west seattle ...\n",
       "3  i am building a referral list of vetted read n...\n",
       "4  programmed 3 hours of experimental movies for ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>americans should never have to fear discrimina...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>eleven years ago the affordable care act becam...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>one year ago we had to close the west seattle ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am building a referral list of vetted read n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>programmed 3 hours of experimental movies for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Stopwords in English language\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Function to clean and tokenize the data\n",
    "def clean_text(text):\n",
    "\n",
    "    #Clear out HTML characters \n",
    "    import html\n",
    "    text=html.unescape(text)\n",
    "\n",
    "    # Replace or remove the characters \n",
    "    replacement_dict={\"https?:\\/\\/.\\S+\":\"\", # Remove hyperlinks\n",
    "                      \"^RT[\\s]+\":\"\", # Remove old style retweet text \"RT\"\n",
    "                      \"\\\\n\":\"\", # Remove newline caharacter\n",
    "                      \"@\\w+.\":\"\", # Remove mentions starting with @\n",
    "                      \"#\":\"\", # Remove the hash # sign\n",
    "                      \"’\":\"'\", # Replace ’ with '\n",
    "                      \"'s\":\" is\", # Replace the contractions\n",
    "                      \"n't\":\" not\",\n",
    "                      \"'m\":\" am\",\n",
    "                      \"'ll\":\" will\",\n",
    "                      \"'d\":\" would\",\n",
    "                      \"'ve\":\n",
    "                      \" have\",\n",
    "                      \"'re\":\" are\",\n",
    "                      \"\\W+\":\" \", # Remove non-word caharacters\n",
    "                      \"^\\s+\":\"\" # Remove whitespace at the beginning\n",
    "                      } \n",
    "\n",
    "    for item in replacement_dict.keys():\n",
    "        text=re.sub(item,replacement_dict[item], text)\n",
    "        \n",
    "    # Separate the words \n",
    "    text = \" \".join([char for char in re.split(\"([A-Z][a-z]+[^A-Z]*)\",text) if char])\n",
    "\n",
    "    # Replace double spaces with one\n",
    "    text = re.sub(\"\\s+\",\" \",text)     \n",
    "\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "   \n",
    "    # Spell check \n",
    "    spell = Speller(lang='en') \n",
    "    text=spell(text)  \n",
    "    \n",
    "    # Return text\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply the function to text column\n",
    "home_timeline_tweets['tweet_text'] = home_timeline_tweets['tweet_text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Display the dataframe\n",
    "home_timeline_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'you took care of everybody else it is now time to take care of yourself too '"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "home_timeline_tweets['tweet_text'][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          tweet_text\n",
       "0  americans should never have to fear discrimina...\n",
       "1  eleven years ago the affordable care act becam...\n",
       "2  one year ago we had to close the west seattle ...\n",
       "3  i am building a referral list of vetted read n...\n",
       "4  programmed 3 hours of experimental movies for ...\n",
       "5  our ingenuity mars helicopter has to meet a se...\n",
       "6  compliments resonate with me because i am 22 a...\n",
       "7  remember when i got that one dm request callin...\n",
       "8  but i am doing this i am all in something good...\n",
       "9  i spoke to the beauty brand consultant she was..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>americans should never have to fear discrimina...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>eleven years ago the affordable care act becam...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>one year ago we had to close the west seattle ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am building a referral list of vetted read n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>programmed 3 hours of experimental movies for ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>our ingenuity mars helicopter has to meet a se...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>compliments resonate with me because i am 22 a...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>remember when i got that one dm request callin...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>but i am doing this i am all in something good...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>i spoke to the beauty brand consultant she was...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "home_timeline_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_timeline_tweets.to_csv('home_timeline_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}